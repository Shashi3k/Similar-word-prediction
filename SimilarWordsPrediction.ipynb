{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsAT8WHY345ezy3m9bYfyf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shashi3k/Similar-word-prediction/blob/main/SimilarWordsPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EEzqCzk4H_lY"
      },
      "outputs": [],
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scrapped_data = urllib.request.urlopen('https://en.wikipedia.org/wiki/Machine_learning')\n",
        "article = scrapped_data.read()\n",
        "\n",
        "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
        "\n",
        "paragraphs = parsed_article.find_all('p')\n",
        "\n",
        "article_text = \"\"\n",
        "\n",
        "for p in paragraphs:\n",
        "    article_text += p.text"
      ],
      "metadata": {
        "id": "UTcAbpfAIBPl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import string\n",
        "    from nltk.corpus import stopwords\n",
        "    import nltk\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "\n",
        "\n",
        "class PreProcessText(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __remove_punctuation(self, text):\n",
        "        \"\"\"\n",
        "        Takes a String\n",
        "        return : Return a String\n",
        "        \"\"\"\n",
        "        message = []\n",
        "        for x in text:\n",
        "            if x in string.punctuation:\n",
        "                pass\n",
        "            else:\n",
        "                message.append(x)\n",
        "        message = ''.join(message)\n",
        "\n",
        "        return message\n",
        "\n",
        "    def __remove_stopwords(self, text):\n",
        "        \"\"\"\n",
        "        Takes a String\n",
        "        return List\n",
        "        \"\"\"\n",
        "        words= []\n",
        "        for x in text.split():\n",
        "\n",
        "            if x.lower() in stopwords.words('english'):\n",
        "                pass\n",
        "            else:\n",
        "                words.append(x)\n",
        "        return words\n",
        "\n",
        "\n",
        "    def token_words(self,text=''):\n",
        "        \"\"\"\n",
        "        Takes String\n",
        "        Return Token also called  list of words that is used to\n",
        "        Train the Model\n",
        "        \"\"\"\n",
        "        message = self.__remove_punctuation(text)\n",
        "        words = self.__remove_stopwords(message)\n",
        "        return words"
      ],
      "metadata": {
        "id": "4Me7jK1-IMHj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "flag = nltk.download(\"stopwords\")\n",
        "\n",
        "if (flag == \"False\" or flag == False):\n",
        "    print(\"Failed to Download Stop Words\")\n",
        "else:\n",
        "    print(\"Downloaded Stop words ...... \")\n",
        "    helper = PreProcessText()\n",
        "    #words = helper.token_words(text=txt)\n",
        "    words = helper.token_words(text=article_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFt1V4I7IPm7",
        "outputId": "91915e49-fa36-40a3-9ddd-b3c240d963a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded Stop words ...... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "hPvuzbJJIRuC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec([words], min_count=1)\n",
        "# model = Word2Vec([words], size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "zCXHOV4CIUdb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = model.wv.key_to_index"
      ],
      "metadata": {
        "id": "cJ3YlwE0IWYj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word = \"machine\"\n",
        "# word_vector = model.wv[word]\n",
        "# print(word_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuS-r5VPWNhE",
        "outputId": "9b768707-1e7b-4962-95e6-a648a9d1ed92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01136554  0.00654503  0.00586945  0.00606971  0.00784848 -0.01094326\n",
            "  0.00202266  0.01240425 -0.00606119 -0.00770489 -0.0022135  -0.01242283\n",
            " -0.00657206  0.00804525  0.00482305  0.00488553  0.00748595  0.00476871\n",
            " -0.00386026 -0.00511132  0.00343446 -0.00437311  0.00955177 -0.01136482\n",
            "  0.00717047  0.00377996 -0.00713808  0.00317001 -0.00416401  0.00714507\n",
            "  0.01336152 -0.00448654  0.00048133 -0.00780578  0.00335674  0.0064191\n",
            "  0.0074155   0.00327399  0.00864733  0.00373742  0.0072996  -0.01041025\n",
            " -0.01118802 -0.00057091 -0.00077223  0.00657787  0.00424311 -0.00183172\n",
            "  0.00326071  0.00393721  0.00858015 -0.01169273 -0.00162911  0.00381881\n",
            " -0.00289538  0.00917817  0.01053574  0.00530548 -0.00404657  0.00875327\n",
            " -0.00740947  0.00358324 -0.00498813 -0.00534943  0.00107382  0.00747564\n",
            "  0.00834622 -0.00366201  0.00378033  0.01067236 -0.00475947 -0.00729595\n",
            "  0.00907448  0.00533369  0.00183142 -0.00493407 -0.00725723 -0.00301282\n",
            "  0.00396233 -0.00352204 -0.01062189  0.003867    0.00303377 -0.00348504\n",
            "  0.0011813  -0.00248415  0.0007595  -0.00758457  0.00559944 -0.00403898\n",
            "  0.00410216 -0.00032082  0.00337792 -0.00763866  0.00156931  0.00532864\n",
            "  0.0062446  -0.00554671 -0.00835467  0.00403553]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim_words = model.wv.most_similar('machine')"
      ],
      "metadata": {
        "id": "CMFi8lZbIpAc"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sim_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gjJ_bqrI3PT",
        "outputId": "862549cd-8bdf-4ec3-eacd-3011a13fb5c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('potential', 0.35734468698501587),\n",
              " ('limitations', 0.3354910612106323),\n",
              " ('microclusters', 0.3322582542896271),\n",
              " ('themselves117', 0.3212181627750397),\n",
              " ('medicine45', 0.3138822913169861),\n",
              " ('routine', 0.31329894065856934),\n",
              " ('foundation', 0.30234000086784363),\n",
              " ('classification', 0.29932352900505066),\n",
              " ('Classic', 0.2890753746032715),\n",
              " ('implemented', 0.28759765625)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the `key_to_index` dictionary instead of the `vocab` attribute\n",
        "X = model.wv.key_to_index"
      ],
      "metadata": {
        "id": "dta3iHI6I7db"
      },
      "execution_count": 14,
      "outputs": []
    }
  ]
}